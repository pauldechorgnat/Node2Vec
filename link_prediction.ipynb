{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing out link prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing useful tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graph_utilities import *\n",
    "from node2vec import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading and loading model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "grqc = load_grqc_from_internet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulating walks:\n",
      "1 / 10\n",
      "2 / 10\n",
      "3 / 10\n",
      "4 / 10\n",
      "5 / 10\n",
      "6 / 10\n",
      "7 / 10\n",
      "8 / 10\n",
      "9 / 10\n",
      "10 / 10\n"
     ]
    }
   ],
   "source": [
    "model = Node2Vec(num_walks=10, dimensions = 100, p = 10, q = 3)\n",
    "model.load_graph(grqc)\n",
    "model.create_model(workers = 8, hierarchical_softmaw = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Node2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/30 - loss 18754300.0\n",
      "epoch 2/30 - loss 12578278.0\n",
      "epoch 3/30 - loss 10717501.0\n",
      "epoch 4/30 - loss 9818438.0\n",
      "epoch 5/30 - loss 8815087.0\n",
      "epoch 6/30 - loss 7916641.5\n",
      "epoch 7/30 - loss 6641129.5\n",
      "epoch 8/30 - loss 5652074.0\n",
      "epoch 9/30 - loss 4571891.5\n",
      "epoch 10/30 - loss 4071485.5\n",
      "epoch 11/30 - loss 3901402.0\n",
      "epoch 12/30 - loss 3417330.0\n",
      "epoch 13/30 - loss 3368642.75\n",
      "epoch 14/30 - loss 3279630.25\n",
      "epoch 15/30 - loss 3053116.5\n",
      "epoch 16/30 - loss 3155094.5\n",
      "epoch 17/30 - loss 3055960.25\n",
      "epoch 18/30 - loss 3048453.5\n",
      "epoch 19/30 - loss 2974704.75\n",
      "epoch 20/30 - loss 2881443.0\n",
      "epoch 21/30 - loss 2883788.25\n",
      "epoch 22/30 - loss 2797062.75\n",
      "epoch 23/30 - loss 2835005.25\n",
      "epoch 24/30 - loss 2909680.5\n",
      "epoch 25/30 - loss 2820576.25\n",
      "epoch 26/30 - loss 2831310.75\n",
      "epoch 27/30 - loss 2816035.25\n",
      "epoch 28/30 - loss 2707929.5\n",
      "epoch 29/30 - loss 2809378.5\n",
      "epoch 30/30 - loss 2763120.0\n"
     ]
    }
   ],
   "source": [
    "model.train(epochs = 30, verbose = True, workers = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_edges = create_fake_edges(graph = grqc, seed = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = building_dataset(graph = grqc, embedding_dict = model.get_embedding_dictionnary(), edges_fake = fake_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[:,:-1]\n",
    "y = data[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Logistic Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .3, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split 1\n",
      "training accuracy 0.7161079615479419\n",
      "test accuracy 0.6867143209267932\n",
      "Confusion Matrix\n",
      "[[1466  578]\n",
      " [ 693 1320]]\n",
      "\n",
      "split 2\n",
      "training accuracy 0.7118560512694109\n",
      "test accuracy 0.7022430367266453\n",
      "Confusion Matrix\n",
      "[[1421  580]\n",
      " [ 628 1428]]\n",
      "\n",
      "split 3\n",
      "training accuracy 0.7086517130884891\n",
      "test accuracy 0.7032289869361598\n",
      "Confusion Matrix\n",
      "[[1493  588]\n",
      " [ 616 1360]]\n",
      "\n",
      "split 4\n",
      "training accuracy 0.710069016514666\n",
      "test accuracy 0.7084052255361104\n",
      "Confusion Matrix\n",
      "[[1477  567]\n",
      " [ 616 1397]]\n",
      "\n",
      "split 5\n",
      "training accuracy 0.711486319940843\n",
      "test accuracy 0.7054473749075671\n",
      "Confusion Matrix\n",
      "[[1461  569]\n",
      " [ 626 1401]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "\n",
    "for train_index, test_index in kf.split(X_train, y_train):\n",
    "    \n",
    "    counter += 1\n",
    "    \n",
    "    X_train_cv = X_train[train_index, :]\n",
    "    X_test_cv = X_train[test_index, :]\n",
    "    y_train_cv = y_train[train_index]\n",
    "    y_test_cv = y_train[test_index]\n",
    "    \n",
    "    lr = LogisticRegression()\n",
    "    \n",
    "    lr.fit(X_train_cv, y_train_cv)\n",
    "    print('split {}'.format(counter))\n",
    "    print('training accuracy {}'.format(lr.score(X_train_cv, y_train_cv)))\n",
    "    print('test accuracy {}'.format(lr.score(X_test_cv, y_test_cv)))\n",
    "    print('Confusion Matrix')\n",
    "    print(confusion_matrix(y_test_cv, lr.predict(X_test_cv)))\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
